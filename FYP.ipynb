{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdulrehman-faisal100/Nuclear-Medicince-CNN/blob/main/FYP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-SUugAN7UADL"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import random\n",
        "import pandas as pd\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_folder(folderName: str):\n",
        "  # Path to the new directory\n",
        "  new_dir_path = os.path.join(\"/content/drive/MyDrive\", folderName)\n",
        "  if not os.path.exists(new_dir_path):\n",
        "      os.makedirs(new_dir_path)\n",
        "  # Path to the zip folder\n",
        "  zip_path = \"/content/drive/MyDrive/temp.zip\"\n",
        "\n",
        "  # Path to the file inside the zip folder\n",
        "  file_path = \"temp/\" + str(folderName) + \"/\"\n",
        "  with open('/content/drive/MyDrive/'+str(folderName)+'.txt', 'r') as file:\n",
        "      # Read each line in the file\n",
        "      for line in file:\n",
        "          # Split the line using a delimiter, such as a comma or a space\n",
        "          img,label = line.split()\n",
        "          # Process the row data\n",
        "          meow = \"temp/\"+str(folderName)\n",
        "          file_path = os.path.join(meow,str(img))\n",
        "\n",
        "          # Extract the file from the zip folder\n",
        "          with zipfile.ZipFile(zip_path) as zip_file:\n",
        "            zip_file.extract(file_path)\n",
        "\n",
        "          # Copy the extracted file to the new directory  \n",
        "          shutil.copy(file_path, new_dir_path)\n",
        "          file_path = ''"
      ],
      "metadata": {
        "id": "tyGe0Xxh9274"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = os.listdir(\"/content/drive/MyDrive/chestLANT/val\")\n",
        "for filename in data_dir:\n",
        "      src_path = os.path.join(\"/content/drive/MyDrive/chestLANT/val\", filename)\n",
        "      dst_path = os.path.join(\"/content/drive/MyDrive/chestLANT\")\n",
        "      shutil.move(src_path, dst_path)"
      ],
      "metadata": {
        "id": "aJ74te1FN9V2"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "f9-DtlKs265H"
      },
      "outputs": [],
      "source": [
        "def train_test_separate(folderName: str):\n",
        "  # set the path to the directory containing the images\n",
        "  data_dir = os.path.join('/content/drive/MyDrive', folderName)\n",
        "\n",
        "  # set the ratio of the validation set\n",
        "  val_ratio = 0.2\n",
        "  img_filenames = os.listdir(data_dir)\n",
        "  print(img_filenames)\n",
        "  # create the subdirectories for the training and validation sets\n",
        "  train_dir = os.path.join(data_dir, 'train')\n",
        "  val_dir = os.path.join(data_dir, 'val')\n",
        "  if not os.path.exists(train_dir):\n",
        "      os.makedirs(train_dir)\n",
        "  if not os.path.exists(val_dir):\n",
        "      os.makedirs(val_dir)\n",
        "  # divide the data into training and validation sets\n",
        "  train_filenames, val_filenames = train_test_split(img_filenames, test_size=val_ratio, random_state=42)\n",
        "\n",
        "  # copy the training set to the output directory\n",
        "  for filename in train_filenames:\n",
        "      src_path = os.path.join(data_dir, filename)\n",
        "      dst_path = os.path.join(train_dir, filename)\n",
        "      shutil.move(src_path, dst_path)\n",
        "\n",
        "  # copy the validation set to the output directory\n",
        "  for filename in val_filenames:\n",
        "      src_path = os.path.join(data_dir, filename)\n",
        "      dst_path = os.path.join(val_dir, filename)\n",
        "      shutil.move(src_path, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classes_separate(folderName: str):\n",
        "  text_file_path = \"/content/drive/MyDrive/\" + str(folderName) + '.txt'\n",
        "  folders = ['train', 'val']\n",
        "  for folder in folders:\n",
        "    dir = \"/content/drive/MyDrive/\"+str(folderName)+\"/\" + str(folder)\n",
        "    # Read the text file and store the image names and labels in a dictionary\n",
        "    labels_dict = {}\n",
        "    with open(text_file_path, 'r') as f:\n",
        "      lines = f.readlines()\n",
        "      for line in lines:\n",
        "        image_name, label = line.strip().split()\n",
        "        labels_dict[image_name] = label\n",
        "\n",
        "    # Create folders for each label in the output directory\n",
        "    for label in set(labels_dict.values()):\n",
        "      label_folder_path = os.path.join(dir, label)\n",
        "      if not os.path.exists(label_folder_path):\n",
        "        os.makedirs(label_folder_path)\n",
        "\n",
        "    # Move the images to their respective label folders\n",
        "    for image_name, label in labels_dict.items():\n",
        "      src_path = os.path.join(dir, image_name)\n",
        "      dst_path = os.path.join(dir, label, image_name)\n",
        "      if os.path.exists(src_path):\n",
        "        shutil.move(src_path, dst_path)"
      ],
      "metadata": {
        "id": "ZqWYRpnSQZhR"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "t4LxtJWFf4LG"
      },
      "outputs": [],
      "source": [
        "def preprocess(folderName: str):\n",
        "  classes = [\"0\",\"1\"]  \n",
        "  folders = [\"train\", \"val\"]\n",
        "  output_dir = \"/content/drive/MyDrive/\" + str(folderName) + \"processed\"\n",
        "  if not os.path.exists(output_dir):\n",
        "      os.makedirs(output_dir)\n",
        "  for i in folders:\n",
        "    for j in classes:\n",
        "      img_dir = os.path.join(\"/content/drive/MyDrive/\",folderName,i,j)\n",
        "      for img1 in os.listdir(img_dir):\n",
        "        img = cv2.imread(str(img_dir)+\"/\"+str(img1))\n",
        "        # Convert the image to grayscale\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply histogram equalization to enhance contrast\n",
        "        #eq = cv2.equalizeHist(gray)\n",
        "\n",
        "        # Apply a bilateral filter to smooth out noise while preserving edges\n",
        "        #bilateral = cv2.bilateralFilter(eq, 9, 75, 75)\n",
        "\n",
        "        # Apply an unsharp mask to sharpen the edges\n",
        "        #unsharp = cv2.addWeighted(eq, 1.5, gray, -0.5, 0)\n",
        "\n",
        "        # Apply a median filter to remove remaining noise\n",
        "        median = cv2.medianBlur(gray, 3)\n",
        "\n",
        "        #unsharp = cv2.addWeighted(median, 1.5, gray, -0.5, 0)\n",
        "\n",
        "        # Apply morphological closing to fill in gaps and smooth out edges\n",
        "        #kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (1,1))\n",
        "        #closed = cv2.morphologyEx(unsharp, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "        # Apply adaptive thresholding to further enhance edges\n",
        "        #thresh = cv2.adaptiveThreshold(closed, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "\n",
        "        # Apply sharpening using Laplacian operator\n",
        "        laplacian = cv2.Laplacian(median, cv2.CV_64F)\n",
        "        sharpened = cv2.convertScaleAbs(median - laplacian)\n",
        "\n",
        "        # Save the sharpened image\n",
        "        output_dir = os.path.join(output_dir,str(i),str(j))\n",
        "        if not os.path.exists(output_dir):\n",
        "          os.makedirs(output_dir)\n",
        "        cv2.imwrite(os.path.join(output_dir,str(img1)), sharpened)\n",
        "        print(os.path.join(output_dir,str(img1)))\n",
        "        output_dir = \"/content/drive/MyDrive/\" + str(folderName) + \"processed\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess(\"chestLANT\")"
      ],
      "metadata": {
        "id": "0_2EbuXtVgjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "dGpIumMcKt66"
      },
      "outputs": [],
      "source": [
        "def train(folderName: str):\n",
        "  # Set the path to the directory containing the bone scan images\n",
        "  train_dir = '/content/drive/MyDrive/'+ folderName+'/train'\n",
        "  test_dir = '/content/drive/MyDrive/'+folderName+'/val'\n",
        "\n",
        "  # Set the batch size, image size, and number of classes\n",
        "  batch_size = 32\n",
        "  num_classes = 2\n",
        "\n",
        "  # Create an instance of the ImageDataGenerator class for data augmentation\n",
        "  datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True)\n",
        "\n",
        "  # Create generators for loading the training and testing data\n",
        "  train_generator = datagen.flow_from_directory(\n",
        "      train_dir,\n",
        "      #target_size=img_size,\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical')\n",
        "\n",
        "  test_generator = datagen.flow_from_directory(\n",
        "      test_dir,\n",
        "      #target_size=img_size,\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical')\n",
        "\n",
        "  # Define the CNN model architecture\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "  # Compile the model and specify the loss function, optimizer, and evaluation metric\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=[tf.keras.metrics.Precision(),tf.keras.metrics.BinaryAccuracy()])\n",
        "\n",
        "  # Train the model on the training data and evaluate on the testing data\n",
        "  history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.n // batch_size,\n",
        "      epochs=10,\n",
        "      validation_data=test_generator,\n",
        "      validation_steps=test_generator.n // batch_size)\n",
        "  # Save the model weights and architecture to disk\n",
        "  model.save_weights(folderName+ 'weights' + '.h5')\n",
        "  model.save(folderName+ 'model' + '.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(\"chestLANTprocessed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "aTABOWUba5uX",
        "outputId": "c959fab0-01a5-48b8-eeeb-0fad94c94257"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2339 images belonging to 2 classes.\n",
            "Found 586 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "11/73 [===>..........................] - ETA: 8:19 - loss: 0.3967 - precision: 0.8722 - binary_accuracy: 0.8722"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-81162e833e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chestLANTprocessed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-77-6357308417b8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(folderName)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;31m# Train the model on the training data and evaluate on the testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   history = model.fit(\n\u001b[0m\u001b[1;32m     59\u001b[0m       \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1gJLRsNSgifxU2HpeYlHCbR6N3_l-kX-N",
      "authorship_tag": "ABX9TyParDaEXJQvxDWTl2lUgDZv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}