{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdulrehman-faisal100/Nuclear-Medicince-CNN/blob/main/FYP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-SUugAN7UADL"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import random\n",
        "import pandas as pd\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_folder(folderName: str):\n",
        "  # Path to the new directory\n",
        "  new_dir_path = os.path.join(\"/content/drive/MyDrive\", folderName)\n",
        "  if not os.path.exists(new_dir_path):\n",
        "      os.makedirs(new_dir_path)\n",
        "  # Path to the zip folder\n",
        "  zip_path = \"/content/drive/MyDrive/temp.zip\"\n",
        "\n",
        "  # Path to the file inside the zip folder\n",
        "  file_path = \"temp/\" + str(folderName) + \"/\"\n",
        "  with open('/content/drive/MyDrive/'+str(folderName)+'.txt', 'r') as file:\n",
        "      # Read each line in the file\n",
        "      for line in file:\n",
        "          # Split the line using a delimiter, such as a comma or a space\n",
        "          img,label = line.split()\n",
        "          # Process the row data\n",
        "          meow = \"temp/\"+str(folderName)\n",
        "          file_path = os.path.join(meow,str(img))\n",
        "\n",
        "          # Extract the file from the zip folder\n",
        "          with zipfile.ZipFile(zip_path) as zip_file:\n",
        "            zip_file.extract(file_path)\n",
        "\n",
        "          # Copy the extracted file to the new directory  \n",
        "          shutil.copy(file_path, new_dir_path)\n",
        "          file_path = ''"
      ],
      "metadata": {
        "id": "tyGe0Xxh9274"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_folder(\"chestLANT\")\n",
        "extract_folder(\"chestLPOST\")\n",
        "extract_folder(\"chestRANT\")\n",
        "extract_folder(\"chestRPOST\")"
      ],
      "metadata": {
        "id": "EX789uuHb0aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "f9-DtlKs265H"
      },
      "outputs": [],
      "source": [
        "def train_test_separate(folderName: str):\n",
        "  # set the path to the directory containing the images\n",
        "  data_dir = os.path.join('/content/drive/MyDrive', folderName)\n",
        "\n",
        "  # set the ratio of the validation set\n",
        "  val_ratio = 0.2\n",
        "  img_filenames = os.listdir(data_dir)\n",
        "  print(img_filenames)\n",
        "  # create the subdirectories for the training and validation sets\n",
        "  train_dir = os.path.join(data_dir, 'train')\n",
        "  val_dir = os.path.join(data_dir, 'val')\n",
        "  if not os.path.exists(train_dir):\n",
        "      os.makedirs(train_dir)\n",
        "  if not os.path.exists(val_dir):\n",
        "      os.makedirs(val_dir)\n",
        "  # divide the data into training and validation sets\n",
        "  train_filenames, val_filenames = train_test_split(img_filenames, test_size=val_ratio, random_state=42)\n",
        "\n",
        "  # copy the training set to the output directory\n",
        "  for filename in train_filenames:\n",
        "      src_path = os.path.join(data_dir, filename)\n",
        "      dst_path = os.path.join(train_dir, filename)\n",
        "      shutil.move(src_path, dst_path)\n",
        "\n",
        "  # copy the validation set to the output directory\n",
        "  for filename in val_filenames:\n",
        "      src_path = os.path.join(data_dir, filename)\n",
        "      dst_path = os.path.join(val_dir, filename)\n",
        "      shutil.move(src_path, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_separate(\"chestLANT\")\n",
        "train_test_separate(\"chestLPOST\")\n",
        "train_test_separate(\"chestRANT\")\n",
        "train_test_separate(\"chestRPOST\")"
      ],
      "metadata": {
        "id": "B6KDvrFGcFvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classes_separate(folderName: str):\n",
        "  text_file_path = \"/content/drive/MyDrive/\" + str(folderName) + '.txt'\n",
        "  folders = ['train', 'val']\n",
        "  for folder in folders:\n",
        "    dir = \"/content/drive/MyDrive/\"+str(folderName)+\"/\" + str(folder)\n",
        "    # Read the text file and store the image names and labels in a dictionary\n",
        "    labels_dict = {}\n",
        "    with open(text_file_path, 'r') as f:\n",
        "      lines = f.readlines()\n",
        "      for line in lines:\n",
        "        image_name, label = line.strip().split()\n",
        "        labels_dict[image_name] = label\n",
        "\n",
        "    # Create folders for each label in the output directory\n",
        "    for label in set(labels_dict.values()):\n",
        "      label_folder_path = os.path.join(dir, label)\n",
        "      if not os.path.exists(label_folder_path):\n",
        "        os.makedirs(label_folder_path)\n",
        "\n",
        "    # Move the images to their respective label folders\n",
        "    for image_name, label in labels_dict.items():\n",
        "      src_path = os.path.join(dir, image_name)\n",
        "      dst_path = os.path.join(dir, label, image_name)\n",
        "      if os.path.exists(src_path):\n",
        "        shutil.move(src_path, dst_path)"
      ],
      "metadata": {
        "id": "ZqWYRpnSQZhR"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_separate(\"chestLANT\")\n",
        "classes_separate(\"chestLPOST\")\n",
        "classes_separate(\"chestRANT\")\n",
        "classes_separate(\"chestRPOST\")"
      ],
      "metadata": {
        "id": "fcrzH5QhcXG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "t4LxtJWFf4LG"
      },
      "outputs": [],
      "source": [
        "def preprocess(folderName: str):\n",
        "  classes = [\"0\",\"1\"]  \n",
        "  folders = [\"train\", \"val\"]\n",
        "  output_dir = \"/content/drive/MyDrive/\" + str(folderName) + \"processed\"\n",
        "  if not os.path.exists(output_dir):\n",
        "      os.makedirs(output_dir)\n",
        "  for i in folders:\n",
        "    for j in classes:\n",
        "      img_dir = os.path.join(\"/content/drive/MyDrive/\",folderName,i,j)\n",
        "      for img1 in os.listdir(img_dir):\n",
        "        img = cv2.imread(str(img_dir)+\"/\"+str(img1))\n",
        "        # Convert the image to grayscale\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply histogram equalization to enhance contrast\n",
        "        #eq = cv2.equalizeHist(gray)\n",
        "\n",
        "        # Apply a bilateral filter to smooth out noise while preserving edges\n",
        "        #bilateral = cv2.bilateralFilter(eq, 9, 75, 75)\n",
        "\n",
        "        # Apply an unsharp mask to sharpen the edges\n",
        "        #unsharp = cv2.addWeighted(eq, 1.5, gray, -0.5, 0)\n",
        "\n",
        "        # Apply a median filter to remove remaining noise\n",
        "        median = cv2.medianBlur(gray, 3)\n",
        "\n",
        "        #unsharp = cv2.addWeighted(median, 1.5, gray, -0.5, 0)\n",
        "\n",
        "        # Apply morphological closing to fill in gaps and smooth out edges\n",
        "        #kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (1,1))\n",
        "        #closed = cv2.morphologyEx(unsharp, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "        # Apply adaptive thresholding to further enhance edges\n",
        "        #thresh = cv2.adaptiveThreshold(closed, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "\n",
        "        # Apply sharpening using Laplacian operator\n",
        "        laplacian = cv2.Laplacian(median, cv2.CV_64F)\n",
        "        sharpened = cv2.convertScaleAbs(median - laplacian)\n",
        "\n",
        "        # Save the sharpened image\n",
        "        output_dir = os.path.join(output_dir,str(i),str(j))\n",
        "        if not os.path.exists(output_dir):\n",
        "          os.makedirs(output_dir)\n",
        "        cv2.imwrite(os.path.join(output_dir,str(img1)), sharpened)\n",
        "        print(os.path.join(output_dir,str(img1)))\n",
        "        output_dir = \"/content/drive/MyDrive/\" + str(folderName) + \"processed\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess(\"chestLANT\")\n",
        "preprocess(\"chestLPOST\")\n",
        "preprocess(\"chestRANT\")\n",
        "preprocess(\"chestRPOST\")"
      ],
      "metadata": {
        "id": "0_2EbuXtVgjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "dGpIumMcKt66"
      },
      "outputs": [],
      "source": [
        "def train(folderName: str):\n",
        "  # Set the path to the directory containing the bone scan images\n",
        "  train_dir = '/content/drive/MyDrive/'+ folderName+'/train'\n",
        "  test_dir = '/content/drive/MyDrive/'+folderName+'/val'\n",
        "\n",
        "  # Set the batch size, image size, and number of classes\n",
        "  batch_size = 32\n",
        "  num_classes = 2\n",
        "\n",
        "  # Create an instance of the ImageDataGenerator class for data augmentation\n",
        "  datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True)\n",
        "\n",
        "  # Create generators for loading the training and testing data\n",
        "  train_generator = datagen.flow_from_directory(\n",
        "      train_dir,\n",
        "      #target_size=img_size,\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical')\n",
        "\n",
        "  test_generator = datagen.flow_from_directory(\n",
        "      test_dir,\n",
        "      #target_size=img_size,\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical')\n",
        "\n",
        "  # Define the CNN model architecture\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "  # Compile the model and specify the loss function, optimizer, and evaluation metric\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=[tf.keras.metrics.Precision(),tf.keras.metrics.BinaryAccuracy()])\n",
        "\n",
        "  # Train the model on the training data and evaluate on the testing data\n",
        "  history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.n // batch_size,\n",
        "      epochs=10,\n",
        "      validation_data=test_generator,\n",
        "      validation_steps=test_generator.n // batch_size)\n",
        "  # Save the model weights and architecture to disk\n",
        "  model.save_weights(folderName+ 'weights' + '.h5')\n",
        "  model.save(folderName+ 'model' + '.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(\"chestLANTprocessed\")"
      ],
      "metadata": {
        "id": "aTABOWUba5uX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(\"chestLPOSTprocessed\")"
      ],
      "metadata": {
        "id": "mi0BqfBzct5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(\"chestRANTprocessed\")"
      ],
      "metadata": {
        "id": "57csDvM-cvAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(\"chestRPOSTprocessed\")"
      ],
      "metadata": {
        "id": "b5OTJgXscviL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1gJLRsNSgifxU2HpeYlHCbR6N3_l-kX-N",
      "authorship_tag": "ABX9TyPjpKNCrFJ3OAJeTucclP99",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}